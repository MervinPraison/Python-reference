{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, SVG\n",
    "\n",
    "Image(filename='Images/multtimeseries.png')\n",
    "SVG(filename='Images/multtimeseriesslice1.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create untidy data with - pd.melt()\n",
    "- melt = turn columns into rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "params:\n",
    "id_vars - columns to keep fixed, NOT melt\n",
    "value_vars - columns to melt, default to melt all columns\n",
    "var_name and value_name - rename columns\n",
    "\"\"\"\n",
    "pd.melt(frame=df, id_vars='name', value_vars=['treatment a', 'treatment b'],\n",
    "       var_name='treatment', value_name='result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: melt tidy data into untidy form\n",
    "\n",
    "# Combine Ozone, Solar.R, Wind, and Temp columns into 1 column\n",
    "\n",
    "# Print the head of airquality\n",
    "print(airquality.head())\n",
    "#    Ozone  Solar.R  Wind  Temp  Month  Day\n",
    "# 0   41.0    190.0   7.4    67      5    1\n",
    "# 1   36.0    118.0   8.0    72      5    2\n",
    "# 2   12.0    149.0  12.6    74      5    3\n",
    "# 3   18.0    313.0  11.5    62      5    4\n",
    "# 4    NaN      NaN  14.3    56      5    5\n",
    "\n",
    "# Melt airquality: airquality_melt\n",
    "airquality_melt = pd.melt(frame=airquality, id_vars=['Month', 'Day'])\n",
    "\n",
    "# Print the head of airquality_melt\n",
    "print(airquality_melt.head())\n",
    "#    Month  Day variable  value\n",
    "# 0      5    1    Ozone   41.0\n",
    "# 1      5    2    Ozone   36.0\n",
    "# 2      5    3    Ozone   12.0\n",
    "# 3      5    4    Ozone   18.0\n",
    "# 4      5    5    Ozone    NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify melted column names with var_name and value_name arg\n",
    "# Melt airquality: airquality_melt\n",
    "airquality_melt = pd.melt(frame=airquality, id_vars=['Month', 'Day'], \n",
    "                          var_name='measurement', value_name='reading')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pivot - un-melt data with pivot()\n",
    "- opposite of melting\n",
    "- pivot = turn unique values into separate columns\n",
    "- args:\n",
    "    - index - columns you don't want to pivot\n",
    "    - columns - columns you want to pivot\n",
    "    - values - values to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tidy = weather.pivot(index='date', columns='element', values='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Using pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the head of airquality_melt\n",
    "print(airquality_melt.head())\n",
    "#        Month  Day measurement  reading\n",
    "#     0      5    1       Ozone     41.0\n",
    "#     1      5    2       Ozone     36.0\n",
    "#     2      5    3       Ozone     12.0\n",
    "#     3      5    4       Ozone     18.0\n",
    "#     4      5    5       Ozone      NaN\n",
    "# Pivot airquality_melt: airquality_pivot\n",
    "airquality_pivot = airquality_melt.pivot_table(index=['Month', 'Day'], \n",
    "                                               columns='measurement', \n",
    "                                               values='reading')\n",
    "\n",
    "# Print the head of airquality_pivot\n",
    "print(airquality_pivot.head())\n",
    "#     measurement  Ozone  Solar.R  Temp  Wind\n",
    "#     Month Day                              \n",
    "#     5     1       41.0    190.0  67.0   7.4\n",
    "#           2       36.0    118.0  72.0   8.0\n",
    "#           3       12.0    149.0  74.0  12.6\n",
    "#           4       18.0    313.0  62.0  11.5\n",
    "#           5        NaN      NaN  56.0  14.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Resetting index of a dataframe (get rid of multiindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the index of airquality_pivot\n",
    "print(airquality_pivot.index)\n",
    "\n",
    "# Reset the index of airquality_pivot: airquality_pivot_reset\n",
    "airquality_pivot_reset = airquality_pivot.reset_index()\n",
    "\n",
    "# Print the new index of airquality_pivot_reset\n",
    "print(airquality_pivot_reset.index)\n",
    "\n",
    "# Print the head of airquality_pivot_reset\n",
    "print(airquality_pivot_reset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Using pivot when you have duplicate entries - pivot_table()\n",
    "- has parameter to deal with duplicate values\n",
    "- example: can aggregate the duplicate values by taking their average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot_table with aggfunc\n",
    "weather2_tidy = weather.pivot_table(values = 'value',\n",
    "                                    index='date', \n",
    "                                    columns='element', \n",
    "                                    aggfunc=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot airquality_dup: airquality_pivot\n",
    "airquality_pivot = airquality_dup.pivot_table(index=['Month', 'Day'], \n",
    "                                              columns='measurement', \n",
    "                                              values='reading', \n",
    "                                              aggfunc=np.mean)\n",
    "\n",
    "# Reset the index of airquality_pivot\n",
    "airquality_pivot = airquality_pivot.reset_index()\n",
    "\n",
    "# Print the head of airquality_pivot\n",
    "print(airquality_pivot.head())\n",
    "\n",
    "# Print the head of airquality\n",
    "print(airquality.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Melting and Parsing\n",
    "- separate 1 column with value that has 2 elements - into 2 separate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable column has age and sex - ie. m014\n",
    "pd.melt(frame=tb, id_vars=['country', 'year'])\n",
    "# create 'gender' column\n",
    "tb_melt['gender'] = tb_melt.variable.str[0]\n",
    "# create age column\n",
    "tb_melt['age_group'] = tb_melt.variable.str[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Splitting a column with .split() and .get()\n",
    "- use when multiple variables are stored in columns with a delimiter, ie. '_'\n",
    "    - ie. column name Deaths_Guinea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt ebola: ebola_melt\n",
    "ebola_melt = pd.melt(ebola, id_vars=['Date', 'Day'], var_name='type_country', value_name='counts')\n",
    "\n",
    "# Create the 'str_split' column\n",
    "ebola_melt['str_split'] = ebola_melt.type_country.str.split('_')\n",
    "\n",
    "# Create the 'type' column\n",
    "ebola_melt['type'] = ebola_melt['str_split'].str.get(0)\n",
    "\n",
    "# Create the 'country' column\n",
    "ebola_melt['country'] = ebola_melt['str_split'].str.get(1)\n",
    "\n",
    "# Print the head of ebola_melt\n",
    "print(ebola_melt.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Concatenating many files - glob() to find files based on pattern\n",
    "Globbing\n",
    "- pattern matching for file names\n",
    "- Wildcards: *?\n",
    "    - '*' for any string\n",
    "        - example: Any csv file: *.csv\n",
    "    - ? for one character\n",
    "        - example: Any single character: file_?.csv\n",
    "- Returns a list of file names\n",
    "- Use this list to load into separate DataFrames\n",
    "\n",
    "Plan\n",
    "- load files from globbing into pandas\n",
    "- add dataframes into a list\n",
    "- concatenate multiple datasets at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# find and concatenate\n",
    "csv_files = glob.glob('*.csv')\n",
    "print(csv_files)\n",
    "\n",
    "# create list of dataframes using a for loop \n",
    "list_data = []\n",
    "for filename in csv_files:\n",
    "    data = pd.read_csv(filename)\n",
    "    list_data.append(data)\n",
    "pd.concat(list_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: Find files that match a pattern\n",
    "\n",
    "# Import necessary modules\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Write the pattern: pattern\n",
    "pattern = '*.csv'\n",
    "\n",
    "# Save all file matches: csv_files\n",
    "csv_files = glob.glob(pattern)\n",
    "\n",
    "# Print the file names\n",
    "print(csv_files)\n",
    "\n",
    "# Load the second file into a DataFrame: csv2\n",
    "csv2 = pd.read_csv(csv_files[1])\n",
    "\n",
    "# Print the head of csv2\n",
    "print(csv2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: iterate and concatenate df for all matches\n",
    "# Create an empty list: frames\n",
    "frames = []\n",
    "\n",
    "#  Iterate over csv_files\n",
    "for csv in csv_files:\n",
    "\n",
    "    #  Read csv into a DataFrame: df\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    # Append df to frames\n",
    "    frames.append(df)\n",
    "\n",
    "# Concatenate frames into a single DataFrame: uber\n",
    "uber = pd.concat(frames)\n",
    "\n",
    "# Print the shape of uber\n",
    "print(uber.shape)\n",
    "\n",
    "# Print the head of uber\n",
    "print(uber.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Merge\n",
    "3 types\n",
    "- one to one\n",
    "- many to one / one to many\n",
    "- many to many\n",
    "\n",
    "Use same function pd.merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 merge: one to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left=state_populations, right=state_codes,\n",
    "        on=None, left_on='state', right_on='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames: o2o\n",
    "o2o = pd.merge(left=site, right=visited, left_on='name', right_on='site')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 merge: many to one / one to many\n",
    "- for duplicates in key, both DataFrames do not have unique keys for a merge \n",
    "- What happens here is that for each duplicated key, every pairwise combination will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames: m2o\n",
    "m2o = pd.merge(left=site, right=visited, left_on='name', right_on='site')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 merge: many to many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge site and visited: m2m\n",
    "m2m = pd.merge(left=site, right=visited, left_on='name', right_on='site')\n",
    "\n",
    "# Merge m2m and survey: m2m\n",
    "m2m = pd.merge(left=m2m, right=survey, left_on='ident', right_on='taken')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "df['column'].astype(str)\n",
    "df['column'].astype(categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object (string) to numeric type with coerce (coerces NaNs)\n",
    "pd.to_numeric(df['column a'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. String manipulation with regex\n",
    "- import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples\n",
    "- 17   \\d*\n",
    "- $17  \\$\\d*\n",
    "- $17.00 \\$\\d*\\.\\d*\n",
    "- Specify 2 digit decimal: $17.89\n",
    "    - \\$\\d*\\.\\d{2}\n",
    "- ^ at beginning and $ at end\n",
    "- $17.895  ^\\$\\d*\\.\\d{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Using regular expressions (aka regex)\n",
    "- compile the pattern\n",
    "- use the pattern to match values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: regex\n",
    "import re\n",
    "pattern = re.compile('\\$\\d*\\.\\d{2}')\n",
    "result = pattern.match('$17.89')\n",
    "bool(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: regex for phone number matching\n",
    "# Import the regular expression module\n",
    "import re\n",
    "\n",
    "# Compile the pattern: prog\n",
    "prog = re.compile('\\d{3}-\\d{3}-\\d{4}')\n",
    "\n",
    "# See if the pattern matches\n",
    "result = prog.match('123-456-7890')\n",
    "print(bool(result))\n",
    "\n",
    "# See if the pattern matches\n",
    "result2 = prog.match('1123-456-7890')\n",
    "print(bool(result2))\n",
    "\n",
    "# output\n",
    "# True\n",
    "# False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: extract numbers from strings\n",
    "# Find numbers in string: 'the recipe calls for 10 strawberries and 1 banana'\n",
    "# Import the regular expression module\n",
    "import re\n",
    "\n",
    "# Find the numeric values: matches\n",
    "matches = re.findall('\\d+', 'the recipe calls for 10 strawberries and 1 banana')\n",
    "\n",
    "# Print the matches\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples: mix of regex patterns\n",
    "# Write the first pattern\n",
    "pattern1 = bool(re.match(pattern='\\d{3}-\\d{3}-\\d{4}', string='123-456-7890'))\n",
    "print(pattern1)\n",
    "\n",
    "# Write the second pattern\n",
    "pattern2 = bool(re.match(pattern='\\$\\d{3}', string='$123.45'))\n",
    "print(pattern2)\n",
    "\n",
    "# Write the third pattern\n",
    "pattern3 = bool(re.match(pattern='\\d*', string='Australia'))\n",
    "print(pattern3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Custom functions to clean data using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: use a custom function to apply regex to create a new column\n",
    "import re\n",
    "from numpy import NaN\n",
    "pattern = re.compile('^\\$\\d*\\.\\d{2}$')\n",
    "\n",
    "# function\n",
    "def diff_money(row, pattern):\n",
    "    # slice the row\n",
    "    icost = row['Initial Cost']\n",
    "    tef = row['Total Est. Fee']\n",
    "    \n",
    "    # if valid value, then convert string to float type\n",
    "    if bool(pattern.match(icost)) and bool(pattern.match(tef)):\n",
    "        icost = icost.replace(\"$\", \"\")\n",
    "        tef = tef.replace(\"$\",\"\")\n",
    "        \n",
    "        icost = float(icost)\n",
    "        tef = float(tef)\n",
    "        \n",
    "        # return difference of the values\n",
    "        return icost - tef\n",
    "    else:\n",
    "        return(NaN)\n",
    "    \n",
    "# apply function\n",
    "df_subset['diff'] = df_subset.apply(diff_money, axis=1, pattern=pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.1 Custom functions to clean data\n",
    "You'll now practice writing functions to clean data.\n",
    "\n",
    "The tips dataset has been pre-loaded into a DataFrame called tips. It has a 'sex' column that contains the values 'Male' or 'Female'. Your job is to write a function that will recode 'Male' to 1, 'Female' to 0, and return np.nan for all entries of 'sex' that are neither 'Male' nor 'Female'.\n",
    "\n",
    "Recoding variables like this is a common data cleaning task. Functions provide a mechanism for you to abstract away complex bits of code as well as reuse code. This makes your code more readable and less error prone.\n",
    "\n",
    "As Dan showed you in the videos, you can use the .apply() method to apply a function across entire rows or columns of DataFrames. However, note that each column of a DataFrame is a pandas Series. Functions can also be applied across Series. Here, you will apply your function over the 'sex' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define recode_sex()\n",
    "def recode_sex(sex_value):\n",
    "\n",
    "    # Return 1 if sex_value is 'Male'\n",
    "    if sex_value == 'Male':\n",
    "        return 1\n",
    "    \n",
    "    # Return 0 if sex_value is 'Female'    \n",
    "    elif sex_value == 'Female':\n",
    "        return 0\n",
    "    \n",
    "    # Return np.nan    \n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to the sex column\n",
    "tips['sex_recode'] = tips.sex.apply(recode_sex)\n",
    "\n",
    "# Print the first five rows of tips\n",
    "print(tips.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.2 Lambda functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: try removing $ sign from a column using 2 methods\n",
    "# Method 1: use .replace(), Method 2: use regex\n",
    "\n",
    "# Write the lambda function using replace\n",
    "tips['total_dollar_replace'] = tips.total_dollar.apply(\n",
    "    lambda x: x.replace('$', ''))\n",
    "\n",
    "# Write the lambda function using regular expressions\n",
    "tips['total_dollar_re'] = tips.total_dollar.apply(\n",
    "    lambda x: re.findall('\\d+\\.\\d+', x)[0])\n",
    "\n",
    "# Print the head of tips\n",
    "print(tips.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Duplicate data\n",
    "- .drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Missing data\n",
    "Handling options:\n",
    "- leave as is\n",
    "- drop them\n",
    "- fill missing value\n",
    "\n",
    "Question\n",
    "- is it random\n",
    "- or is it a systemic problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values\n",
    "tips_dropped = tips_nan.dropna()\n",
    "tips_dropped info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with .fillna() - options: provided value, summary statistic\n",
    "tips_nan['sex'] = tips_nan['sex'].fillna('missing')\n",
    "# fill mssing values from multiple columns\n",
    "tips_nan[['total_bill', 'size']] = tips_nan[['total_bill', 'size']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing value with a test statistic\n",
    "mean_value = tips_nan['tip'].mean()\n",
    "print(mean_value)\n",
    "tips_nan['tip'] = tips_nan['tip'].fillna(mean_value)\n",
    "tips_nan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='Images/multtimeseries.png')\n",
    "SVG(filename='Images/multtimeseriesslice1.svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
