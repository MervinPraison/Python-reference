{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering for NLP in Python\n",
    "Rounak Banik - Data Scientist at Fractal Analytics\n",
    "\n",
    "Rounak is a Young India Fellow and the author of the book, Hands-on Recommendation Systems with Python. He currently works as a Data Science Fellow with the QuantumBlack division of McKinsey and Company. He obtained his B.Tech degree in Electronics & Communication Engineering from IIT Roorkee."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary\n",
    "1. Basic features and readability scores\n",
    "2. Text preprocessing, POS tagging, and NER (named entity recognition)\n",
    "3. N-Gram models - for sentiment analysis\n",
    "4. TF-IDF and cosine similarity scores - for recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to NLP feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction to NLP feature engineering\n",
    " - Welcome to Feature Engineering for NLP in Python! I am Rounak and I will be your instructor for this course. In this course, you will learn to extract useful features out of text and convert them into formats that are suitable for machine learning algorithms.\n",
    "\n",
    "2. Numerical data\n",
    " - For any ML algorithm, data fed into it must be in tabular form and all the training features must be numerical. Consider the Iris dataset. Every training instance has exactly four numerical features. The ML algorithm uses these four features to train and predict if an instance belongs to class iris-virginica, iris-setosa or iris-versicolor.\n",
    "\n",
    "3. One-hot encoding\n",
    " - ML algorithms can also work with categorical data provided they are converted into numerical form through one-hot encoding. Let's say you have a categorical feature 'sex' with two categories 'male' and 'female'.\n",
    "\n",
    "4. One-hot encoding\n",
    " - One-hot encoding will convert this feature into two features,\n",
    "\n",
    "5. One-hot encoding\n",
    " - 'sex_male' and 'sex_female' such that each male instance has a 'sex_male' value of 1 and 'sex_female' value of 0. For females, it is the vice versa.\n",
    "\n",
    "6. One-hot encoding with pandas\n",
    " - To do this in code, we use pandas' get_dummies() function. Let's import pandas using the alias pd. We can then pass our dataframe df into the pd.get_dummies() function and pass a list of features to be encoded as the columns argument. Not mentioning columns will lead pandas to automatically encode all non-numerical features. Finally, we overwrite the original dataframe with the encoded version by assigning the dataframe returned by get_dummies() back to df.\n",
    "\n",
    "7. Textual data\n",
    " - Consider a movie reviews dataset. This data cannot be utilized by any machine learning or ML algorithm. The training feature 'review' isn't numerical. Neither is it categorical to perform one-hot encoding on.\n",
    "\n",
    "8. Text pre-processing\n",
    " - We need to perform two steps to make this dataset suitable for ML. The first is to standardize the text. This involves steps like converting words to lowercase and their base form. For instance, 'Reduction' gets lowercased and then converted to its base form, reduce. We will cover these concepts in more detail in subsequent lessons.\n",
    "\n",
    "9. Vectorization\n",
    " - After preprocessing, the reviews are converted into a set of numerical training features through a process known as vectorization. After vectorization, our original review dataset gets converted\n",
    "\n",
    "10. Vectorization\n",
    " - into something like this. We will learn techniques to achieve this in later lessons.\n",
    "\n",
    "11. Basic features\n",
    " - We can also extract certain basic features from text. It maybe useful to know the word count, character count and average word length of a particular text. While working with niche data such as tweets, it also maybe useful to know how many hashtags have been used in a tweet. This tweet by Silverado Records,for instance, uses two.\n",
    "\n",
    "12. POS tagging\n",
    " - So far, we have seen how to extract features out of an entire body of text. Some NLP applications may require you to extract features for individual words. For instance, you may want to do parts-of-speech tagging to know the different parts-of-speech present in your text as shown. As an example, consider the sentence 'I have a dog'. POS tagging will label each word with its corresponding part-of-speech.\n",
    "\n",
    "13. Named Entity Recognition\n",
    " - You may also want to know perform named entity recognition to find out if a particular noun is referring to a person, organization or country. For instance, consider the sentence \"Brian works at DataCamp\". Here, there are two nouns \"Brian\" and \"DataCamp\". Brian refers to a person whereas DataCamp refers to an organization.\n",
    "\n",
    "14. Concepts covered\n",
    " - Therefore, broadly speaking, this course will teach you how to conduct text preprocessing, extract certain basic features, word features and convert documents into a set of numerical features (using a process known as vectorization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the features of df1\n",
    "print(df1.columns)\n",
    "\n",
    "# Perform one-hot encoding\n",
    "df1 = pd.get_dummies(df1, columns=['feature 5'])\n",
    "\n",
    "# Print the new features of df1\n",
    "print(df1.columns)\n",
    "\n",
    "# Print first five rows of df1\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Basic feature extraction\n",
    " - In this video, we will learn to extract certain basic features  from text. While not very powerful, they can give us a good idea of the text we are dealing with.\n",
    "\n",
    "2. Number of characters\n",
    " - The most basic feature we can extract from text is the number of characters, including whitespaces. For instance, the string \"I don't know.\" has 13 characters. The number of characters is the length of the string. Python gives us a built-in len() function which returns the length of the string passed into it. The output will be 13 here too. If our dataframe df has a textual feature (say 'review'), we can compute the number of characters for each review and store it as a new feature 'num_chars' by using the pandas dataframe apply method. This is done by creating df['num_chars'] and assigning it to df['review'].apply(len).\n",
    "\n",
    "3. Number of words\n",
    " - Another feature we can compute is the number of words. Assuming that every word is separated by a space, we can use a string's split() method to convert it into a list where every element is a word. In this example, the string Mary had a little lamb is split to create a list containing the words Mary, had, a, little and lamb. We can now compute the number of words by computing the number of elements in this list using len().\n",
    "\n",
    "4. Number of words\n",
    " - To do this for a textual feature in a dataframe, we first define a function that takes in a string as an argument and returns the number of words in it. The steps followed inside the function are similar as before. We then pass this function word_count into apply. We create df['num_words'] and assign it to df['review'].apply(word_count).\n",
    "\n",
    "5. Average word length\n",
    " - Let's now compute the average length of words in a string. Let's define a function avg_word_length() which takes in a string and returns the average word length. We first split the string into words and compute the length of each word. Next, we compute the average word length by dividing the sum of the lengths of all words by the number of words.\n",
    "\n",
    "6. Average word length\n",
    " - We can now pass this into apply() to generate a average word length feature like before.\n",
    "\n",
    "7. Special features\n",
    " - When working with data such as tweets, it maybe useful to compute the number of hashtags or mentions used. This tweet by DataCamp, for instance, has one mention upendra_35 which begins with an @ and two hashtags, PySpark and Spark which begin with a #.\n",
    "\n",
    "8. Hashtags and mentions\n",
    " - Let's write a function that computes the number of hashtags in a string. We split the string into words. We then use list comprehension to create a list containing only those words that are hashtags. We do this using the startswith method of strings to find out if a word begins with #. The final step is to return the number of elements in this list using len. The procedure to compute number of mentions is identical except that we check if a word starts with @. Let's see this function in action. When we pass a string \"@janedoe This is my first tweet! #FirstTweet #Happy\", the function returns 2 which is indeed the number of hashtags in the string.\n",
    "\n",
    "9. Other features\n",
    " - There are other basic features we can compute such as number of sentences, number of paragraphs, number of words starting with an uppercase, all-capital words, numeric quantities etc. The procedure to do this is extremely similar to the ones we've already covered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T02:50:56.162104Z",
     "start_time": "2021-09-26T02:50:56.152521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"I don't know.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to column\n",
    "# create a 'num_chars' feature\n",
    "df['num_chars'] = df['review'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of words - assume separated by space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T02:53:13.035455Z",
     "start_time": "2021-09-26T02:53:13.031450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mary', 'had', 'a', 'little', 'lamb.']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "text = \"Mary had a little lamb.\"\n",
    "words = text.split()\n",
    "print(words)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature in df\n",
    "# function that returns number of words in string\n",
    "def word_count(string):\n",
    "    # split the string into words\n",
    "    words = string.split()\n",
    "    # return length of words list\n",
    "    return len(words)\n",
    "\n",
    "# create num_words feature in df\n",
    "df['num_words'] = df['review'].apply(word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that returns avg word length\n",
    "def avg_word_length(x):\n",
    "    # split the string into words\n",
    "    words = x.split()\n",
    "    # compute length of each word and store in a separate list\n",
    "    word_lengths = [len(word) for word in words]\n",
    "    # compute average word length\n",
    "    avg_word_length = sum(word_lengths)/len(words)\n",
    "    # return average word length\n",
    "    return(avg_word_length)\n",
    "\n",
    "# create a new feature avg_word_length\n",
    "df['avg_word_length'] = df['review'].apply(doc_density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special features like hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T03:00:26.421776Z",
     "start_time": "2021-09-26T03:00:26.416597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that returns number of hashtages\n",
    "def hashtag_count(string):\n",
    "    # split the string into words\n",
    "    words = string.split()\n",
    "    # create a list of hashtags\n",
    "    hashtags = [word for word in words if word.startswith('#')]\n",
    "    # return number of hashtags\n",
    "    return len(hashtags)\n",
    "\n",
    "hashtag_count(\"@janedoe This is my first tweet! #FirstTweet #Happy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other features\n",
    "- number of sentences\n",
    "- number of paragraphs\n",
    "- words starting with an uppercase\n",
    "- all-capital words\n",
    "- numeric quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
